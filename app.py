import streamlit as st
import requests
import tempfile
import os
import tensorflow as tf
import numpy as np
from PIL import Image


MODEL_URL = "https://github.com/Imaaneea/cat_dog_classification_images/raw/master/cats_and_dogs_model.tflite"

@st.cache_resource  # Cache pour √©viter de t√©l√©charger √† chaque ex√©cution
def load_model():
    """T√©l√©charge et charge le mod√®le TFLite"""
    with st.spinner("T√©l√©chargement du mod√®le..."):
        response = requests.get(MODEL_URL, stream=True)
        if response.status_code == 200:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".tflite") as temp_model_file:
                for chunk in response.iter_content(chunk_size=1024):
                    temp_model_file.write(chunk)
                model_path = temp_model_file.name
        else:
            st.error("Erreur lors du t√©l√©chargement du mod√®le.")
            return None

    if os.path.exists(model_path):
        st.write(f"‚úÖ Mod√®le t√©l√©charg√© √† : {model_path}")
        st.write(f"üìÇ Taille du fichier : {os.path.getsize(model_path)} octets")
    else:
        st.error("‚õî Le fichier du mod√®le n'a pas √©t√© t√©l√©charg√© correctement.")
        return None

    try:
        model = tf.lite.Interpreter(model_path=model_path)
        model.allocate_tensors()
        st.success("‚úÖ Mod√®le charg√© avec succ√®s !")
        return model
    except Exception as e:
        st.error(f"‚õî Erreur lors du chargement du mod√®le : {str(e)}")
        return None

def predict_image(image_file, model):
    """Pr√©dit si l'image est un chat ou un chien."""
    try:
        # Charger et pr√©traiter l'image
        image = Image.open(image_file).convert("RGB")
        image = image.resize((150, 150))  
        image_array = np.array(image) / 255.0  
        image_array = np.expand_dims(image_array, axis=0).astype(np.float32)  

        # R√©cup√©rer les d√©tails du mod√®le
        input_details = model.get_input_details()
        output_details = model.get_output_details()

        # V√©rifier si le format d'entr√©e du mod√®le est correct
        st.write(f"üìå Input Shape attendu : {input_details[0]['shape']}")
        st.write(f"üìå Image Shape fournie : {image_array.shape}")

        # Passer l'image au mod√®le
        model.set_tensor(input_details[0]['index'], image_array)
        model.invoke()

        # R√©cup√©rer la sortie
        prediction = model.get_tensor(output_details[0]['index'])[0][0]

        # D√©terminer la classe
        class_names = ["Chat üê±", "Chien üê∂"]
        result = {
            "value": class_names[int(prediction > 0.5)],
            "prob": round(float(prediction), 4),
        }
        return result

    except Exception as e:
        st.error(f"‚õî Erreur lors de la pr√©diction : {str(e)}")
        return {"value": "Erreur", "prob": 0}

# Charger le mod√®le
model = load_model()

# Interface Streamlit
st.write("""
# MSDE5 : Deep Learning Project
## Cat Vs Dog Classification
""")

st.sidebar.image("https://miro.medium.com/v2/resize:fit:1400/format:webp/1*EvMbMNRHm_aOf1n4tDO1Xg.jpeg", width=250)
st.sidebar.write("This is a classification model of cat and dog images")
st.markdown("This project was made by : **KHAWLA BADDAR** & **Aymane ElAZHARI**")
st.write("Upload an image to classify whether it's a cat or a dog.")

uploaded_file = st.file_uploader("Choose a file", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)

    result = predict_image(uploaded_file, model)

    # Afficher le r√©sultat
    st.success(f"üîç Pr√©diction : {result['value']}")
    st.success(f"üìä Probabilit√© : {result['prob']}")
